{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc1973f",
   "metadata": {},
   "source": [
    "# Lesson 2: Your First NAT Workflow\n",
    "In this lesson, you'll learn how to create and run NAT workflows.\n",
    "\n",
    "NAT workflows are defined in YAML configuration files that specify your agent's capabilities, which LLM to use, and which tools it can access. This config-driven approach means you can test different models or swap tools by changing a few lines‚Äîno code refactoring required.\n",
    "You'll build a simple climate Q&A assistant, test it locally, deploy it as a REST API, and preview the final application you'll build by the end of the course.\n",
    "\n",
    "<div style=\"background-color: #e7f3fe; border-left: 6px solid #2196F3; padding: 15px; margin: 10px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üéØ What you'll do:</h4>\n",
    "<ul>\n",
    "<li>Define your first agent in a YAML config file</li>\n",
    "<li>Test your workflow locally before deploying</li>\n",
    "<li>Launch it as a REST API and send live requests</li>\n",
    "<li>See how NAT automatically generates interactive API documentation</li>\n",
    "<li>Preview the UI you'll build for your agent</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "**Note:** All dependencies are pre-installed on the DeepLearning.AI platform. If you're running this in your own environment, uncomment and run the following code to install NAT and LangChain endpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2afb7a0-580b-405e-bfa7-23110a55c3df",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#install Nemo Agent Toolkit and langchain dependency\n",
    "!pip install nvidia-nat\n",
    "!pip install \"nvidia-nat[langchain]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c9eff-752a-4427-a8d1-76df611f2911",
   "metadata": {},
   "source": [
    "### Getting your own API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb725070-09d6-4738-8f38-18fabf965e6b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e8f4f8; border-left: 4px solid #0076ce; padding: 15px; margin: 10px 0; border-radius: 4px;\">\n",
    "    <p style=\"margin: 0; font-size: 14px; line-height: 1.6;\">\n",
    "        <strong>üìù Note:</strong> An API key is already configured in the course environment. If you're running this code in your own environment, visit <a href=\"https://build.nvidia.com\" target=\"_blank\" style=\"color: #0076ce;\">https://build.nvidia.com</a> to create a free account and generate an API key, then set it as an environment variable using a <code>.env</code> file or <code>export NVIDIA_API_KEY='your-key'</code>.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e0eb9e-804f-48ba-9292-20ddaa7de28f",
   "metadata": {
    "height": 181
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: Yes\n"
     ]
    }
   ],
   "source": [
    "# load env variables \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "   \n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "   \n",
    "# Verify the key loaded\n",
    "print(\"API key loaded:\", \"Yes\" if os.getenv('NVIDIA_API_KEY') else \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77c380-5093-4712-9319-a447e9d6b0ca",
   "metadata": {},
   "source": [
    "## Create the NAT Configuration\n",
    "Start by creating `config.yml`. This YAML file defines your entire workflow in a declarative way‚Äî no Python code needed.\n",
    "\n",
    "<div style=\"background-color: #fff3cd; border-left: 6px solid #ffc107; padding: 15px; margin: 15px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üìã Config File Structure</h4>\n",
    "Your config has two main sections:\n",
    "<br><br>\n",
    "<strong>llms:</strong> Defines the language models available to your workflow. Each model gets a name (like <code>climate_llm</code>) that you'll reference later. Here you specify:\n",
    "<ul>\n",
    "<li>Which model to use (<code>meta/llama-3.1-70b-instruct</code>)</li>\n",
    "<li>Where to find it (NVIDIA's API endpoint)</li>\n",
    "<li>Generation parameters (temperature, max tokens)</li>\n",
    "</ul>\n",
    "<strong>workflow:</strong> Defines how your agent behaves. In this simple example:\n",
    "<ul>\n",
    "<li><code>_type: chat_completion</code> means it's a basic conversational agent</li>\n",
    "<li><code>llm_name</code> connects to the LLM you defined above</li>\n",
    "<li><code>system_prompt</code> sets the agent's personality and expertise</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac63b9ba",
   "metadata": {
    "height": 334
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yml\n",
    "\n",
    "llms:\n",
    "  climate_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-70b-instruct\n",
    "    base_url: $NVIDIA_BASE_URL\n",
    "    api_key: $NVIDIA_API_KEY\n",
    "    temperature: 0.7\n",
    "    max_tokens: 2048\n",
    "\n",
    "workflow:\n",
    "  _type: chat_completion\n",
    "  llm_name: climate_llm\n",
    "  system_prompt: |\n",
    "    You are a knowledgeable climate science assistant. You help users understand \n",
    "    climate data, weather patterns, and global temperature trends. Be accurate, \n",
    "    informative, and cite scientific consensus when appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb1af32",
   "metadata": {},
   "source": [
    "## Test Your Workflow\n",
    "Before deploying as an API, test your workflow locally using `nat run`. \n",
    "\n",
    "<div style=\"background-color: #e7f3fe; border-left: 6px solid #2196F3; padding: 15px; margin: 15px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üîç What <code>nat run</code> Does</h4>\n",
    "<ol>\n",
    "<li>Reads your config file</li>\n",
    "<li>Initializes the specified LLM</li>\n",
    "<li>Sends your query through the workflow</li>\n",
    "<li>Returns the result</li>\n",
    "</ol>\n",
    "This is perfect for quick testing before deploying as an API.\n",
    "</div>\n",
    "\n",
    "Try these three test questions that progress from general knowledge to more specific data questions:\n",
    "\n",
    "### Question 1: Climate Basics\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; border-left: 6px solid #4CAF50; padding: 15px; margin: 20px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üìä Test 1: Simple Definition (Easy)</h4>\n",
    "<p><strong>Type:</strong> <span style=\"background-color: #4CAF50; color: white; padding: 3px 8px; border-radius: 3px;\">General Knowledge</span></p>\n",
    "<p><strong>Expected Result:</strong> Clear, accurate answer from LLM's training data</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694e041-9569-44ca-b5fa-d738cea42014",
   "metadata": {},
   "source": [
    "<div><p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\">\n",
    "&nbsp; <b>Different Run Results:</b> The output visualizations generated may differ from those shown in the video.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e08ce4",
   "metadata": {
    "height": 96
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-17 19:49:49 - INFO     - matplotlib.font_manager:1639 - generated new fontManager\n",
      "2025-12-17 19:49:50 - INFO     - nat.cli.commands.start:192 - Starting NAT from config file: 'config.yml'\n",
      "2025-12-17 19:49:50 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "/usr/local/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:171: UserWarning: http://jupyter-api-proxy.internal.dlai/rev-proxy/nvidia does not end in /v1, you may have inference and listing issues. This check will be deprecated in the next release. Please ensure /v1 is appended to the provided URL\n",
      "  warnings.warn(\n",
      "\n",
      "Configuration Summary:\n",
      "--------------------\n",
      "Workflow Type: chat_completion\n",
      "Number of Functions: 0\n",
      "Number of Function Groups: 0\n",
      "Number of LLMs: 1\n",
      "Number of Embedders: 0\n",
      "Number of Memory: 0\n",
      "Number of Object Stores: 0\n",
      "Number of Retrievers: 0\n",
      "Number of TTC Strategies: 0\n",
      "Number of Authentication Providers: 0\n",
      "\n",
      "2025-12-17 19:49:55 - INFO     - nat.front_ends.console.console_front_end_plugin:102 - --------------------------------------------------\n",
      "\u001b[32mWorkflow Result:\n",
      "['Weather and climate are two related but distinct concepts in the field of meteorology.\\n\\n**Weather** refers to short-term atmospheric conditions in a specific place at a specific time. It includes temperature, humidity, cloudiness, wind, precipitation, and other factors that can change from day to day, hour to hour, or even minute to minute. Weather is what you experience when you step outside on a given day, such as a sunny day, a rainy day, or a hot summer day.\\n\\n**Climate**, on the other hand, refers to long-term average atmospheric conditions in a particular region. It describes the typical weather patterns, temperature ranges, and precipitation amounts that occur over a period of years, decades, or even centuries. Climate is what you expect to experience in a given region over a long period, such as a cold winter in the Arctic or a hot summer in the desert.\\n\\nTo illustrate the difference, consider this analogy:\\n\\n* Weather is like a person\\'s mood, which can change from day to day.\\n* Climate is like a person\\'s personality, which is a long-term characteristic that shapes their overall behavior.\\n\\nAccording to the Intergovernmental Panel on Climate Change (IPCC), \"Climate is the long-term average atmospheric condition in a particular region, while weather is the short-term, local-scale condition\" (IPCC, 2013).\\n\\nIn summary, weather is the day-to-day conditions, while climate is the long-term average pattern of those conditions.\\n\\nWould you like to know more about climate or weather?']\u001b[39m\n",
      "--------------------------------------------------\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Simple question about climate basics\n",
    "!nat run \\\n",
    "  --config_file config.yml \\\n",
    "  --input \"What is the difference between weather and climate?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76094341-d532-48aa-b159-42b8779e1fca",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin: 15px 0; font-family: monospace;\">\n",
    "<strong>Expected Output:</strong>\n",
    "<pre style=\"margin: 10px 0; white-space: pre-wrap;\">\n",
    "Contains a statement along the lines of: Weather refers to short-term atmospheric conditions (days to weeks), while climate describes long-term patterns (typically 30+ years). Weather changes frequently; climate represents average conditions over time.\n",
    "</pre>\n",
    "</div>\n",
    "\n",
    "### Question 2: Global Temperature Trends\n",
    "<div style=\"background-color: #fff3e0; border-left: 6px solid #ff9800; padding: 15px; margin: 20px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üìä Test 2: Scientific Fact (Moderate)</h4>\n",
    "<p><strong>Type:</strong> <span style=\"background-color: #ff9800; color: white; padding: 3px 8px; border-radius: 3px;\">Scientific Knowledge</span></p>\n",
    "<p><strong>Expected Result:</strong> Fact-based answer with approximate figures</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db4113",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-17 19:49:59 - INFO     - nat.cli.commands.start:192 - Starting NAT from config file: 'config.yml'\n",
      "2025-12-17 19:50:00 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "/usr/local/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:171: UserWarning: http://jupyter-api-proxy.internal.dlai/rev-proxy/nvidia does not end in /v1, you may have inference and listing issues. This check will be deprecated in the next release. Please ensure /v1 is appended to the provided URL\n",
      "  warnings.warn(\n",
      "\n",
      "Configuration Summary:\n",
      "--------------------\n",
      "Workflow Type: chat_completion\n",
      "Number of Functions: 0\n",
      "Number of Function Groups: 0\n",
      "Number of LLMs: 1\n",
      "Number of Embedders: 0\n",
      "Number of Memory: 0\n",
      "Number of Object Stores: 0\n",
      "Number of Retrievers: 0\n",
      "Number of TTC Strategies: 0\n",
      "Number of Authentication Providers: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question about global temperature trends\n",
    "!nat run \\\n",
    "  --config_file config.yml \\\n",
    "  --input \"How much has global average \\\n",
    "  temperature increased since pre-industrial times?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb0aac0-3b2d-4463-b759-54fc33d29fc6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin: 15px 0; font-family: monospace;\">\n",
    "<strong>Expected Output:</strong>\n",
    "<pre style=\"margin: 10px 0; white-space: pre-wrap;\">\n",
    "Global average temperature has increased approximately 1.1-1.2¬∞C since pre-industrial times (1850-1900). This warming is primarily due to human activities, particularly greenhouse gas emissions.\n",
    "</pre>\n",
    "</div>\n",
    "\n",
    "### Question 3: Specific Data Query\n",
    "<div style=\"background-color: #ffebee; border-left: 6px solid #f44336; padding: 15px; margin: 20px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üìä Test 3: Specific Data (Reveals Limitation)</h4>\n",
    "<p><strong>Type:</strong> <span style=\"background-color: #f44336; color: white; padding: 3px 8px; border-radius: 3px;\">Data-Specific</span></p>\n",
    "<p><strong>Expected Result:</strong> Agent can't provide exact data‚Äîwill either admit it or hallucinate</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47482342",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "# A data-specific question that would benefit from real data analysis\n",
    "!nat run \\\n",
    "  --config_file config.yml \\\n",
    "  --input \"What were the exact temperature anomalies \\\n",
    "  for the top 5 warmest countries in 2023?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85639eb2-ad23-456a-b57c-6bbe3cd581a2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin: 15px 0; font-family: monospace;\">\n",
    "<strong>Expected Output:</strong>\n",
    "<pre style=\"margin: 10px 0; white-space: pre-wrap;\">\n",
    "The agent might say something like: \"I don't have access to specific 2023 temperature anomaly data for individual countries. To answer this accurately, I would need to query a climate database.\" It might also just hallucinate a response. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aef22c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e7f3fe; border-left: 6px solid #2196F3; padding: 10px;\">\n",
    "<strong>Notice the Limitation:</strong> <br>\n",
    "Your agent can answer general climate questions, but it can't analyze real data or perform calculations. It's limited to knowledge from its training set.\n",
    "<br><br>\n",
    "In the next lesson, you'll register Python functions as tools‚Äîgiving your agent the ability to load climate datasets, calculate temperature anomalies, and generate visualizations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469acd92-0a53-4c0e-890f-408524a70353",
   "metadata": {},
   "source": [
    "## Deploy as an API\n",
    "Now make your agent accessible through a REST API endpoint using `nat serve`.\n",
    "\n",
    "In production, you can run the following line in a terminal:\n",
    "```bash\n",
    "nat serve --config_file config.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f730b3cc-21f5-41fe-be2f-4b8198246da3",
   "metadata": {},
   "source": [
    "But since you're in a Jupyter notebook, you'll use Python's `subprocess` to start the server in the background:\n",
    "### Start the local API Server:\n",
    "\n",
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> <b>Note <code>(Server Starting)</code>:</b> The API server can take about 60 seconds to be ready for use. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95bd0a4-7a2c-4fe2-a12a-230837fb402c",
   "metadata": {
    "height": 334
   },
   "outputs": [],
   "source": [
    "# use subprocess since you are running in a notebook\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Clean up old processes if you ran notebook before\n",
    "!pkill -f \"nat serve\" 2>/dev/null || true\n",
    "time.sleep(2)\n",
    "\n",
    "# Start NAT with explicit IPv4 host\n",
    "nat_process = subprocess.Popen(\n",
    "    [\"nat\", \"serve\", \"--config_file\", \"config.yml\", \"--host\", \"127.0.0.1\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Wait and let it print to console naturally\n",
    "time.sleep(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec1d45e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f3e5f5; border-left: 6px solid #9c27b0; padding: 15px; margin: 15px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üí° What's Happening Here?</h4>\n",
    "<ul>\n",
    "<li><strong>subprocess.Popen</strong> starts the NAT server as a separate process</li>\n",
    "<li><strong>stderr=subprocess.DEVNULL</strong> suppresses informational logs (not actual errors)</li>\n",
    "<li><strong>Server runs on</strong> <code>http://localhost:8000</code> by default</li>\n",
    "<li><strong>NAT automatically generates</strong> API documentation at <code>http://localhost:8000/docs</code></li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"background-color: #e8f5e9; border-left: 6px solid #4CAF50; padding: 15px; margin: 15px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üéØ What NAT Handles Automatically</h4>\n",
    "<table style=\"width: 100%; border-collapse: collapse; margin-top: 10px;\">\n",
    "    <tr style=\"background-color: #4CAF50; color: white;\">\n",
    "        <th style=\"padding: 10px; text-align: left; border: 1px solid #ddd;\">Feature</th>\n",
    "        <th style=\"padding: 10px; text-align: left; border: 1px solid #ddd;\">What It Does</th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: white;\">\n",
    "        <td style=\"padding: 10px; border: 1px solid #ddd;\"><strong>API Routing</strong></td>\n",
    "        <td style=\"padding: 10px; border: 1px solid #ddd;\">Creates standard REST endpoints automatically</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: white;\">\n",
    "        <td style=\"padding: 10px; border: 1px solid #ddd;\"><strong>Request Validation</strong></td>\n",
    "        <td style=\"padding: 10px; border: 1px solid #ddd;\">Validates incoming requests match expected format</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #f9f9f9;\">\n",
    "        <td style=\"padding: 10px; border: 1px solid #ddd;\"><strong>Error Handling</strong></td>\n",
    "        <td style=\"padding: 10px; border: 1px solid #ddd;\">Returns proper HTTP status codes and error messages</td>\n",
    "    </tr>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "### Test the API\n",
    "Now send a POST request to your running NAT API server- NAT uses the OpenAI-compatible chat completions format, so any tool that works with OpenAI's API will work with your NAT agent. The API server will use the API key and base URL previously set in `config.yml`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04417d0",
   "metadata": {
    "height": 453
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Test the API endpoint\n",
    "response = requests.post(\n",
    "    \"http://localhost:8000/v1/chat/completions\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    json={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What causes El Ni√±o and how does it affect global weather?\"\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    ")\n",
    "\n",
    "# Parse and display the response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(result[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c7baf4",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f3e5f5; border-left: 6px solid #9c27b0; padding: 15px; margin: 15px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üí° Response Structure</h4>\n",
    "NAT returns a JSON object matching OpenAI's format:\n",
    "<ul>\n",
    "<li><code>choices[0].message.content</code> contains the agent's text response</li>\n",
    "<li><code>usage</code> shows token counts (prompt tokens + completion tokens)</li>\n",
    "<li><code>model</code> shows which LLM was used</li>\n",
    "</ul>\n",
    "<br>\n",
    "This OpenAI-compatible format means your NAT agents can drop into existing applications that use OpenAI's API.\n",
    "</div>\n",
    "\n",
    "## Quick UI Demo\n",
    "Throughout the course, you'll enhance your workflow with tools, tracing, and evaluation. In the final lesson, you'll deploy a UI that lets users interact with your agent through a chat interface.\n",
    "\n",
    "‚ú® **Run the following code to preview the final UI you'll build (video may not reflect changes in the current version):** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d54aff",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from ui_manager import ui_manager\n",
    "\n",
    "ui_manager.start()\n",
    "ui_manager.show_ui_link()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f3fd1c-af81-42d9-913a-0668fd56045a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fff3cd; border-left: 6px solid #ffc107; padding: 15px; margin: 15px 0;\">\n",
    "<h4 style=\"margin-top: 0;\">üí¨ Try These Questions</h4>\n",
    "<ul>\n",
    "<li>\"What is climate change?\"</li>\n",
    "<li>\"How do scientists measure global temperature?\"</li>\n",
    "<li>\"What were the warmest years on record?\" (notice it can't give precise data yet)</li>\n",
    "</ul>\n",
    "<br>\n",
    "<strong>What you'll notice:</strong> The agent can answer general questions well, but struggles with specific data queries. That's what you'll fix in the next lesson by adding tools.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3c892",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "Before moving to the next lesson, stop the running processes to free up resources and avoid port conflicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d5c91",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "ui_manager.stop()\n",
    "nat_process.terminate()\n",
    "nat_process.wait()\n",
    "print(\"‚úÖ Server stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3eac7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "<div style=\"background-color: #e3f2fd; border: 2px solid #2196F3; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "<h3 style=\"color: #1976d2; margin-top: 0;\">üéâ Congratulations on Building Your First NAT Workflow!</h3>\n",
    "<div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin: 20px 0;\">\n",
    "    <div style=\"background-color: white; padding: 15px; border-radius: 5px;\">\n",
    "        <h4 style=\"color: #4CAF50; margin-top: 0;\">‚úÖ What You Built</h4>\n",
    "        <ul>\n",
    "            <li>A YAML-based agent configuration (no Python code required)</li>\n",
    "            <li>A climate Q&A assistant with custom system prompt</li>\n",
    "            <li>A REST API endpoint with OpenAI-compatible format</li>\n",
    "            <li>A preview of the chat interface you'll deploy</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"background-color: white; padding: 15px; border-radius: 5px;\">\n",
    "        <h4 style=\"color: #2196F3; margin-top: 0;\">üîß Key Concepts</h4>\n",
    "        <ul>\n",
    "            <li><strong>Config-driven development</strong> - Change models/settings without code changes</li>\n",
    "            <li><strong>nat run</strong> - Test locally before deploying</li>\n",
    "            <li><strong>nat serve</strong> - Deploy as API instantly</li>\n",
    "            <li><strong>OpenAI compatibility</strong> - Works with existing tools</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "<div style=\"background-color: white; padding: 15px; border-radius: 5px; margin-top: 15px;\">\n",
    "<h4 style=\"color: #4CAF50; margin-top: 0;\">‚úÖ Current Capabilities</h4>\n",
    "<ul>\n",
    "<li>Answers general climate questions from LLM's training data</li>\n",
    "<li>Serves responses through a REST API</li>\n",
    "<li>Can connect to any chat UI or application</li>\n",
    "<li>Auto-generates API documentation</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"background-color: #fff3cd; padding: 15px; border-radius: 5px; margin-top: 15px;\">\n",
    "<h4 style=\"margin-top: 0;\">‚ö†Ô∏è Current Limitation</h4>\n",
    "No access to real climate datasets‚Äîyour agent can't:\n",
    "<ul>\n",
    "<li>Analyze actual temperature data</li>\n",
    "<li>Perform calculations on climate records</li>\n",
    "<li>Generate visualizations from data</li>\n",
    "<li>Answer questions like \"What were the 5 warmest years on record?\"</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"background-color: #d4edda; padding: 15px; border-radius: 5px; margin-top: 15px;\">\n",
    "<h4 style=\"margin-top: 0;\">üöÄ Next Lesson: Add Tools</h4>\n",
    "You'll register Python functions as tools, giving your agent the ability to:\n",
    "<ul>\n",
    "<li>Load real climate data from CSV files</li>\n",
    "<li>Calculate temperature anomalies and trends</li>\n",
    "<li>Generate data visualizations</li>\n",
    "<li>Answer specific questions with real data</li>\n",
    "<li>Coordinate multiple tools to solve complex problems</li>\n",
    "</ul>\n",
    "Your agent will transform from a knowledge-only chatbot into a data analysis system.\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
