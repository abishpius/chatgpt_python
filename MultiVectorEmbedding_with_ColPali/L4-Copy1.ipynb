{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c83e4e6",
   "metadata": {},
   "source": [
    "# L4 - MUVERA Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbeb99a",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2ed2e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872a95a",
   "metadata": {},
   "source": [
    "The following cell is not in the video and just ensures output later in this notebook will render properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92394d16e370b16",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acfbf6",
   "metadata": {},
   "source": [
    "#### Loading MUVERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a743e591eab0c9d",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "from fastembed.postprocess.muvera import Muvera\n",
    "\n",
    "muvera = Muvera(\n",
    "    # Colpali individual token embedding dimensionality\n",
    "    dim=128,\n",
    "    # 64 clusters\n",
    "    k_sim=6,\n",
    "    # Reduce the dimensionality with Random Projection\n",
    "    dim_proj=16,\n",
    "    # Repeat the process 20 times and concat\n",
    "    # the individual results\n",
    "    r_reps=20,\n",
    "    # Random seed to make sure the results\n",
    "    # are reproducible (default: 42)\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235579bajwk",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "LOAD_PRECOMPUTED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fae395b",
   "metadata": {},
   "source": [
    "#### Loading Sample Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eqk6la0oz6",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 document pages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ro_shared_data/pdfs/screenshots/AI4E_W1-page-0...</td>\n",
       "      <td>[[-0.1533203125, 0.030517578125, 0.1357421875,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ro_shared_data/pdfs/screenshots/AI4E_W1-page-0...</td>\n",
       "      <td>[[-0.04150390625, 0.1640625, 0.1708984375, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ro_shared_data/pdfs/screenshots/AI4E_W1-page-0...</td>\n",
       "      <td>[[-0.1240234375, -0.025634765625, 0.0668945312...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  ro_shared_data/pdfs/screenshots/AI4E_W1-page-0...   \n",
       "1  ro_shared_data/pdfs/screenshots/AI4E_W1-page-0...   \n",
       "2  ro_shared_data/pdfs/screenshots/AI4E_W1-page-0...   \n",
       "\n",
       "                                     image_embedding  \n",
       "0  [[-0.1533203125, 0.030517578125, 0.1357421875,...  \n",
       "1  [[-0.04150390625, 0.1640625, 0.1708984375, 0.0...  \n",
       "2  [[-0.1240234375, -0.025634765625, 0.0668945312...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import load_sample_image_embeddings\n",
    "\n",
    "# Load or compute image embeddings using helper function\n",
    "# that only loads a sample of data\n",
    "images_df = load_sample_image_embeddings(\n",
    "    load_precomputed=LOAD_PRECOMPUTED,\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(images_df)} document pages\")\n",
    "images_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79bcb1",
   "metadata": {},
   "source": [
    "#### Generating MUVERA Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jyuqy0bn3xk",
   "metadata": {
    "height": 317
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MUVERA embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 56.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original shape: (1031, 128)\n",
      "MUVERA FDE shape: (20480,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Process all documents with MUVERA\n",
    "muvera_embeddings = []\n",
    "\n",
    "for _, row in tqdm(\n",
    "    images_df.iterrows(), total=len(images_df), desc=\"MUVERA embeddings\"\n",
    "):\n",
    "    # Apply MUVERA compression\n",
    "    muvera_fde = muvera.process_document(row[\"image_embedding\"])\n",
    "    muvera_embeddings.append(muvera_fde)\n",
    "\n",
    "# Add to dataframe\n",
    "images_df[\"muvera_embedding\"] = muvera_embeddings\n",
    "\n",
    "print(f\"\\nOriginal shape: {images_df['image_embedding'][0].shape}\")\n",
    "print(f\"MUVERA FDE shape: {images_df['muvera_embedding'][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55787068",
   "metadata": {},
   "source": [
    "#### Generating Query Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mqdd2fyhn6a",
   "metadata": {
    "height": 232
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coffee mug', 'size vs performance tradeoff', 'one learning algorithm']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import load_or_compute_query_embeddings\n",
    "\n",
    "# Load or compute query embeddings using helper function\n",
    "queries_df = load_or_compute_query_embeddings(\n",
    "    load_precomputed=LOAD_PRECOMPUTED,\n",
    ")\n",
    "\n",
    "# Extract queries and query embeddings for later use\n",
    "queries = queries_df[\"query\"].tolist()\n",
    "query_embeddings = queries_df[\"query_embedding\"].tolist()\n",
    "\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "auf7pkg7r0q",
   "metadata": {
    "height": 232
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query shape: (18, 128)\n",
      "MUVERA query FDE shape: (20480,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Process queries with MUVERA\n",
    "muvera_query_embeddings = []\n",
    "\n",
    "for qe in query_embeddings:\n",
    "    qe_array = np.stack(qe)\n",
    "    muvera_qe = muvera.process_query(qe_array)\n",
    "    muvera_query_embeddings.append(muvera_qe)\n",
    "\n",
    "print(f\"Original query shape: {np.stack(query_embeddings[0]).shape}\")\n",
    "print(f\"MUVERA query FDE shape: {muvera_query_embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8635e1ea",
   "metadata": {},
   "source": [
    "#### Creating Qdrant Collection and Adding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9w37y4sq3n",
   "metadata": {
    "height": 606
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "collection_name = \"colpali-optimizations\"\n",
    "\n",
    "# Connect to Qdrant\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Delete if exists\n",
    "if client.collection_exists(collection_name):\n",
    "    client.delete_collection(collection_name)\n",
    "\n",
    "# Create collection with dual vectors\n",
    "client.create_collection(\n",
    "    collection_name,\n",
    "    vectors_config={\n",
    "        # Original ColPali multivectors\n",
    "        \"colpali_original\": models.VectorParams(\n",
    "            size=128,\n",
    "            distance=models.Distance.DOT,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM,\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0),\n",
    "            on_disk=True,\n",
    "        ),\n",
    "        # MUVERA fixed-dimensional encodings\n",
    "        \"muvera_fde\": models.VectorParams(\n",
    "            size=20480,  # 64 √ó 16 √ó 20\n",
    "            distance=models.Distance.DOT,\n",
    "            on_disk=True,\n",
    "            # No multivector config - single vector with HNSW\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f0fb93f78651a",
   "metadata": {
    "height": 555
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing and inserting documents: 0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Expect this cell may take several minutes to finish\n",
    "from tqdm import tqdm\n",
    "from helper import yield_muvera_embeddings\n",
    "\n",
    "# Stream through embeddings and upsert into Qdrant collection\n",
    "for i, (image_path, vectors) in enumerate(\n",
    "    tqdm(\n",
    "        yield_muvera_embeddings(\n",
    "            muvera=muvera,\n",
    "            load_precomputed=LOAD_PRECOMPUTED,\n",
    "        ),\n",
    "        desc=\"Processing and inserting documents\",\n",
    "    )\n",
    "):\n",
    "    client.upsert(\n",
    "        collection_name,\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=i,\n",
    "                vector={\n",
    "                    \"colpali_original\": vectors[\"colpali_original\"],\n",
    "                    \"muvera_fde\": vectors[\"muvera_fde\"],\n",
    "                },\n",
    "                payload={\n",
    "                    \"image_path\": image_path,\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "print(f\"\\nInserted {i+1} documents into {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170ea848e9ffc16",
   "metadata": {
    "height": 198
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "sleep(5.0)\n",
    "while True:\n",
    "    collection_info = client.get_collection(collection_name)\n",
    "    if collection_info.status == models.CollectionStatus.GREEN:\n",
    "        break\n",
    "    sleep(5.0)\n",
    "\n",
    "print(f\"Collection has indexed all the data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f122ed",
   "metadata": {},
   "source": [
    "#### Creating ColPali and MUVERA Search Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2tv8ycmi",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def search_colpali(query_embedding, limit=5):\n",
    "    \"\"\"Search using original ColPali multivectors\"\"\"\n",
    "    start = time.time()\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_embedding,\n",
    "        using=\"colpali_original\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "    search_time = time.time() - start\n",
    "    return results.points, search_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de4447-2755-44a3-bc26-e64781e7ed20",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "def search_muvera(query_embedding, limit=5):\n",
    "    \"\"\"Search using MUVERA compressed vectors\"\"\"\n",
    "    start = time.time()\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_embedding,\n",
    "        using=\"muvera_fde\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "    search_time = time.time() - start\n",
    "    return results.points, search_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a22b9",
   "metadata": {},
   "source": [
    "#### Comparing ColPali and MUVERA Search Peformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qbe8xjwzotq",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "from helper import compare_search_methods\n",
    "\n",
    "# Query 1: \"coffee mug\"\n",
    "query_idx = 0\n",
    "\n",
    "# Compare results (runs searches 10 times internally)\n",
    "result_q1 = compare_search_methods(\n",
    "    baseline_search_fn=lambda: search_colpali(\n",
    "        query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    comparison_search_fn=lambda: search_muvera(\n",
    "        muvera_query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    baseline_name=\"ColPali\",\n",
    "    comparison_name=\"MUVERA\",\n",
    "    query_text=queries[query_idx],\n",
    "    limit=5,\n",
    "    n_runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811jzje0f9",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# Query 2: \"size vs performance tradeoff\"\n",
    "query_idx = 1\n",
    "\n",
    "# Compare results (runs searches 10 times internally)\n",
    "result_q2 = compare_search_methods(\n",
    "    baseline_search_fn=lambda: search_colpali(\n",
    "        query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    comparison_search_fn=lambda: search_muvera(\n",
    "        muvera_query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    baseline_name=\"ColPali\",\n",
    "    comparison_name=\"MUVERA\",\n",
    "    query_text=queries[query_idx],\n",
    "    limit=5,\n",
    "    n_runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flutodyty8",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# Query 3: \"one learning algorithm\"\n",
    "query_idx = 2\n",
    "\n",
    "# Compare results (runs searches 10 times internally)\n",
    "result_q3 = compare_search_methods(\n",
    "    baseline_search_fn=lambda: search_colpali(\n",
    "        query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    comparison_search_fn=lambda: search_muvera(\n",
    "        muvera_query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    baseline_name=\"ColPali\",\n",
    "    comparison_name=\"MUVERA\",\n",
    "    query_text=queries[query_idx],\n",
    "    limit=5,\n",
    "    n_runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nbzr298xpn",
   "metadata": {
    "height": 266
   },
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "results = [result_q1, result_q2, result_q3]\n",
    "\n",
    "# Calculate averages\n",
    "avg_speedup = np.mean([r[\"avg_speedup\"] for r in results])\n",
    "median_speedup = np.mean([r[\"median_speedup\"] for r in results])\n",
    "avg_precision = np.mean([r[\"precision\"] for r in results])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AVERAGE PERFORMANCE (across 3 queries)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Average speedup (mean): {avg_speedup:.1f}x faster\")\n",
    "print(f\"Average speedup (median): {median_speedup:.1f}x faster\")\n",
    "print(f\"Average precision@5: {avg_precision:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a1b43e",
   "metadata": {},
   "source": [
    "#### Comparing Two-Stage Retrieval and ColPali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rfjnhbmeos9",
   "metadata": {
    "height": 538
   },
   "outputs": [],
   "source": [
    "def two_stage_retrieval(query_colpali, query_muvera, limit=5):\n",
    "    \"\"\"\n",
    "    Two-stage retrieval using prefetch:\n",
    "    1. Fast MUVERA search for candidates\n",
    "    2. Rerank with ColPali for accuracy\n",
    "\n",
    "    Returns tuple of (results, search_time) like other search functions.\n",
    "    \"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Single API call with prefetch mechanism\n",
    "    final_results = client.query_points(\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=query_muvera,\n",
    "                using=\"muvera_fde\",\n",
    "                limit=limit * 10,  # Ten times more\n",
    "            )\n",
    "        ],\n",
    "        collection_name=collection_name,\n",
    "        query=query_colpali,\n",
    "        using=\"colpali_original\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    total_time = time.time() - start\n",
    "\n",
    "    return final_results.points, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fjetveo0w64",
   "metadata": {
    "height": 385
   },
   "outputs": [],
   "source": [
    "# Test two-stage retrieval on first query\n",
    "query_idx = 0\n",
    "print(f'Query: \"{queries[query_idx]}\"')\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use compare_search_methods to calculate precision vs ColPali\n",
    "two_stage_result_q1 = compare_search_methods(\n",
    "    baseline_search_fn=lambda: search_colpali(\n",
    "        query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    comparison_search_fn=lambda: two_stage_retrieval(\n",
    "        query_embeddings[query_idx],\n",
    "        muvera_query_embeddings[query_idx],\n",
    "        limit=5,\n",
    "    ),\n",
    "    baseline_name=\"ColPali\",\n",
    "    comparison_name=\"Two-stage\",\n",
    "    query_text=queries[query_idx],\n",
    "    limit=5,\n",
    "    n_runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db30f4-2b6d-4933-852f-6cdbfa3849a6",
   "metadata": {
    "height": 385
   },
   "outputs": [],
   "source": [
    "# Test two-stage retrieval on second query\n",
    "query_idx = 1\n",
    "print(f'Query: \"{queries[query_idx]}\"')\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use compare_search_methods to calculate precision vs ColPali\n",
    "two_stage_result_q2 = compare_search_methods(\n",
    "    baseline_search_fn=lambda: search_colpali(\n",
    "        query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    comparison_search_fn=lambda: two_stage_retrieval(\n",
    "        query_embeddings[query_idx],\n",
    "        muvera_query_embeddings[query_idx],\n",
    "        limit=5,\n",
    "    ),\n",
    "    baseline_name=\"ColPali\",\n",
    "    comparison_name=\"Two-stage\",\n",
    "    query_text=queries[query_idx],\n",
    "    limit=5,\n",
    "    n_runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zwqouy686",
   "metadata": {
    "height": 385
   },
   "outputs": [],
   "source": [
    "# Test two-stage retrieval on third query\n",
    "query_idx = 2\n",
    "print(f'Query: \"{queries[query_idx]}\"')\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use compare_search_methods to calculate precision vs ColPali\n",
    "two_stage_result_q3 = compare_search_methods(\n",
    "    baseline_search_fn=lambda: search_colpali(\n",
    "        query_embeddings[query_idx], limit=5\n",
    "    ),\n",
    "    comparison_search_fn=lambda: two_stage_retrieval(\n",
    "        query_embeddings[query_idx],\n",
    "        muvera_query_embeddings[query_idx],\n",
    "        limit=5,\n",
    "    ),\n",
    "    baseline_name=\"ColPali\",\n",
    "    comparison_name=\"Two-stage\",\n",
    "    query_text=queries[query_idx],\n",
    "    limit=5,\n",
    "    n_runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783wom385on",
   "metadata": {
    "height": 487
   },
   "outputs": [],
   "source": [
    "# Collect all two-stage results\n",
    "two_stage_results = [\n",
    "    two_stage_result_q1,\n",
    "    two_stage_result_q2,\n",
    "    two_stage_result_q3,\n",
    "]\n",
    "\n",
    "# Calculate averages\n",
    "avg_two_stage_time = np.mean(\n",
    "    [r[\"comparison_avg_time\"] for r in two_stage_results]\n",
    ")\n",
    "avg_precision = np.mean([r[\"precision\"] for r in two_stage_results])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TWO-STAGE RETRIEVAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nAverage two-stage time: {avg_two_stage_time * 1000:.2f}ms\")\n",
    "print(\n",
    "    f\"  Query 1: {two_stage_results[0]['comparison_avg_time'] * 1000:.2f}ms\"\n",
    ")\n",
    "print(\n",
    "    f\"  Query 2: {two_stage_results[1]['comparison_avg_time'] * 1000:.2f}ms\"\n",
    ")\n",
    "print(\n",
    "    f\"  Query 3: {two_stage_results[2]['comparison_avg_time'] * 1000:.2f}ms\"\n",
    ")\n",
    "print(f\"\\nAverage precision@5 vs ColPali: {avg_precision:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
