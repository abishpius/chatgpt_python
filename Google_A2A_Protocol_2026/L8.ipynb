{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3280b815-0cca-4ac5-9338-73ff43bbb7b9",
   "metadata": {},
   "source": [
    "# Lesson 8 - Creating an A2A Healthcare Provider Agent using LangGraph and MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53361338",
   "metadata": {},
   "source": [
    "In this lesson, you will build a third agent: a Healthcare Provider Agent. This agent demonstrates a powerful combination of technologies:\n",
    "1.  **MCP (Model Context Protocol)**: You will build a server that exposes a tool to find doctors from a JSON file.\n",
    "2.  **LangGraph**: You will build an agent that uses this MCP tool.\n",
    "3.  **A2A**: You will wrap the LangGraph agent in an A2A server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba7ac04-5a55-4dfc-8c85-3086cbcc51a5",
   "metadata": {},
   "source": [
    "## 8.1. Create the MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0f204",
   "metadata": {},
   "source": [
    "First, you will define an MCP server using `FastMCP`. This server exposes a tool called `list_doctors` which queries a local `doctors.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mcpserver.py\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# Initialize the server\n",
    "mcp = FastMCP(\"doctorserver\")\n",
    "\n",
    "# Load Data\n",
    "doctors: list = json.loads(Path(\"../data/doctors.json\").read_text())\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def list_doctors(state: str | None = None, city: str | None = None) -> list[dict]:\n",
    "    \"\"\"This tool returns a list of doctors practicing in a specific location. The search is case-insensitive.\n",
    "\n",
    "    Args:\n",
    "        state: The two-letter state code (e.g., \"CA\" for California).\n",
    "        city: The name of the city or town (e.g., \"Boston\").\n",
    "\n",
    "    Returns:\n",
    "        A JSON string representing a list of doctors matching the criteria.\n",
    "        If no criteria are provided, an error message is returned.\n",
    "        Example: '[{\"name\": \"Dr John James\", \"specialty\": \"Cardiology\", ...}]'\n",
    "    \"\"\"\n",
    "    # Input validation: ensure at least one search term is given.\n",
    "    if not state and not city:\n",
    "        return [{\"error\": \"Please provide a state or a city.\"}]\n",
    "\n",
    "    target_state = state.strip().lower() if state else None\n",
    "    target_city = city.strip().lower() if city else None\n",
    "\n",
    "    return [\n",
    "        doc\n",
    "        for doc in doctors\n",
    "        if (not target_state or doc[\"address\"][\"state\"].lower() == target_state)\n",
    "        and (not target_city or doc[\"address\"][\"city\"].lower() == target_city)\n",
    "    ]\n",
    "\n",
    "\n",
    "# Kick off server if file is run\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176aefc4-e4e3-4cc8-8f19-9e91cf952b0b",
   "metadata": {},
   "source": [
    "## 8.2. Test with LangGraph and MCP Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e4e686",
   "metadata": {},
   "source": [
    "Now you will verify that you can connect to the MCP server and use it within a LangChain/LangGraph agent. You use `MultiServerMCPClient` to connect to the local script via `stdio` transport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd93b3f-eb0e-416d-8e99-c5b742ac4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from langchain.agents import create_agent\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_mcp_adapters.sessions import StdioConnection\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from helpers import authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5761b-d767-44e0-a4f5-e231e60dc7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials, project_id = authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059618a0-d640-4e96-8186-c621fcf9a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "location = \"us-central1\"\n",
    "base_url = f\"{os.getenv('GOOGLE_VERTEX_BASE_URL')}/v1/projects/{project_id}/locations/{location}/endpoints/openapi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbe22e",
   "metadata": {},
   "source": [
    "**Note:** The `base_url` looks a bit different from the one used in the video. This is because it was adapted to work in this learning environment. If you'd like to run the notebooks locally, make sure to check the [course repo](https://github.com/holtskinner/A2AWalkthrough/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a91a66-8722-4114-80f0-921113a97941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a7da4-031e-4740-894d-3d2f21ea6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"find_healthcare_providers\": StdioConnection(\n",
    "            transport=\"stdio\",\n",
    "            command=\"uv\",\n",
    "            args=[\"run\", \"mcpserver.py\"],\n",
    "        )\n",
    "    }\n",
    ")\n",
    "tools = asyncio.run(mcp_client.get_tools())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af393ecf-c160-420e-8003-495219e21515",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    ChatOpenAI(\n",
    "        model=\"openai/gpt-oss-20b-maas\",\n",
    "        openai_api_key=credentials.token,\n",
    "        openai_api_base=base_url,\n",
    "    ),\n",
    "    tools,\n",
    "    name=\"HealthcareProviderAgent\",\n",
    "    system_prompt=\"\"\"Your task is to find and list healthcare providers \n",
    "    using the find_healthcare_providers MCP Tool based on the users query. \n",
    "    Only use providers based on the response from the tool.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45467f-2f4b-44f8-9297-2366003ec97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I'm based in Austin, TX. Are there any Psychiatrists near me?\"\n",
    "response = await agent.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260abd1-af0e-4f1f-aadd-24bab804d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response[\"messages\"][-1].content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe890515-251f-42a2-ab8d-430d5212b354",
   "metadata": {},
   "source": [
    "## 8.3. Define the Provider Agent Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e33425",
   "metadata": {},
   "source": [
    "You will now encapsulate this logic into a `ProviderAgent` class and append it to `agents.py`. This class handles the MCP client connection and agent initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351955a9-1fed-4522-a85c-40cfe44ec6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a agents.py\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_mcp_adapters.sessions import StdioConnection\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from helpers import authenticate\n",
    "\n",
    "class ProviderAgent:\n",
    "    def __init__(self) -> None:\n",
    "        credentials, project_id = authenticate()\n",
    "        location = \"us-central1\"\n",
    "        base_url = f\"{os.getenv('GOOGLE_VERTEX_BASE_URL')}/v1/projects/{project_id}/locations/{location}/endpoints/openapi\"\n",
    "        \n",
    "        self.mcp_client = MultiServerMCPClient(\n",
    "            {\n",
    "                \"find_healthcare_providers\": StdioConnection(\n",
    "                    transport=\"stdio\",\n",
    "                    command=\"uv\",\n",
    "                    args=[\"run\", \"mcpserver.py\"],\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.credentials = credentials\n",
    "        self.base_url = base_url\n",
    "        self.agent = None\n",
    "\n",
    "    async def initialize(self):\n",
    "        \"\"\"Initialize the agent asynchronously.\"\"\"\n",
    "        tools = await self.mcp_client.get_tools()\n",
    "        self.agent = create_agent(\n",
    "            ChatOpenAI(\n",
    "                model=\"openai/gpt-oss-20b-maas\",\n",
    "                openai_api_key=self.credentials.token,\n",
    "                openai_api_base=self.base_url,\n",
    "            ),\n",
    "            tools,\n",
    "            name=\"HealthcareProviderAgent\",\n",
    "            system_prompt=\"\"\"Your task is to find and list providers using \n",
    "            the find_healthcare_providers MCP Tool based on the users query. \n",
    "            Only use providers based on the response from the tool. Output \n",
    "            the information in a table.\"\"\",\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    async def answer_query(self, prompt: str) -> str:\n",
    "        if self.agent is None:\n",
    "            raise RuntimeError(\"\"\"Agent not initialized. Call initialize() \n",
    "            first.\"\"\")\n",
    "\n",
    "        response = await self.agent.ainvoke(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934147ee-f53e-4325-8286-0afe8fccd71d",
   "metadata": {},
   "source": [
    "## 8.4. Test the Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f70d3",
   "metadata": {},
   "source": [
    "Verify the class works as expected before wrapping it in A2A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ceb55-223b-47c9-a910-f801e9fd77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import ProviderAgent\n",
    "\n",
    "agent = await ProviderAgent().initialize()\n",
    "result = await agent.answer_query(\n",
    "    \"I'm based in Austin, TX. Are there any Psychiatrists near me?\"\n",
    ")\n",
    "\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132cbda-edcb-4029-93e3-179b533b9fc4",
   "metadata": {},
   "source": [
    "## 8.5. Wrap in A2A Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a650ec",
   "metadata": {},
   "source": [
    "Finally, create the `a2a_provider_agent.py` server file. This uses the standard A2A wrapping pattern you learned in Lesson 3, but with the added complexity of asynchronous initialization for the MCP client in the `ProviderAgentExecutor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24954e6-0ef5-4159-bb17-500db8f87d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../a2a_provider_agent.py\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uvicorn\n",
    "from a2a.server.agent_execution import AgentExecutor, RequestContext\n",
    "from a2a.server.apps import A2AStarletteApplication\n",
    "from a2a.server.events import EventQueue\n",
    "from a2a.server.request_handlers import DefaultRequestHandler\n",
    "from a2a.server.tasks import InMemoryTaskStore\n",
    "from a2a.types import (\n",
    "    AgentCapabilities,\n",
    "    AgentCard,\n",
    "    AgentSkill,\n",
    ")\n",
    "from a2a.utils import new_agent_text_message\n",
    "from agents import ProviderAgent\n",
    "\n",
    "class ProviderAgentExecutor(AgentExecutor):\n",
    "    \"\"\"This is an agent for finding healthcare providers based on location and specialty.\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        # Don't await in __init__ - it's not async\n",
    "        self.agent = None\n",
    "    \n",
    "    async def _ensure_initialized(self) -> None:\n",
    "        \"\"\"Lazy initialization of the agent.\"\"\"\n",
    "        if self.agent is None:\n",
    "            self.agent = await ProviderAgent().initialize()\n",
    "    \n",
    "    async def execute(\n",
    "        self,\n",
    "        context: RequestContext,\n",
    "        event_queue: EventQueue,\n",
    "    ) -> None:\n",
    "        await self._ensure_initialized()\n",
    "        \n",
    "        prompt = context.get_user_input()\n",
    "        response = await self.agent.answer_query(prompt)\n",
    "        await event_queue.enqueue_event(new_agent_text_message(response))\n",
    "    \n",
    "    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:\n",
    "        pass\n",
    "\n",
    "def main():\n",
    "    print(\"Running Healthcare Provider Agent\")\n",
    "    load_dotenv()\n",
    "    \n",
    "    HOST = os.environ.get(\"AGENT_HOST\", \"localhost\")\n",
    "    PORT = int(os.environ.get(\"PROVIDER_AGENT_PORT\", 9997))\n",
    "    \n",
    "    skill = AgentSkill(\n",
    "        id=\"find_healthcare_providers\",\n",
    "        name=\"Find Healthcare Providers\",\n",
    "        description=\"Finds and lists healthcare providers based on user's location and specialty.\",\n",
    "        tags=[\"healthcare\", \"providers\", \"doctor\", \"psychiatrist\"],\n",
    "        examples=[\n",
    "            \"Are there any Psychiatrists near me in Boston, MA?\",\n",
    "            \"Find a pediatrician in Springfield, IL.\",\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    agent_card = AgentCard(\n",
    "        name=\"HealthcareProviderAgent\",\n",
    "        description=\"An agent that can find and list healthcare providers based on a user's location and desired specialty.\",\n",
    "        url=f\"http://{HOST}:{PORT}/\",\n",
    "        version=\"1.0.0\",\n",
    "        default_input_modes=[\"text\"],\n",
    "        default_output_modes=[\"text\"],\n",
    "        capabilities=AgentCapabilities(streaming=False),\n",
    "        skills=[skill],\n",
    "    )\n",
    "    \n",
    "    request_handler = DefaultRequestHandler(\n",
    "        agent_executor=ProviderAgentExecutor(),\n",
    "        task_store=InMemoryTaskStore(),\n",
    "    )\n",
    "    \n",
    "    server = A2AStarletteApplication(\n",
    "        agent_card=agent_card,\n",
    "        http_handler=request_handler,\n",
    "    )\n",
    "    \n",
    "    uvicorn.run(server.build(), host=HOST, port=PORT)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9365bcd-0d92-4e3e-ade5-f546c27df497",
   "metadata": {},
   "source": [
    "## 8.6. Run the Provider Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e2aac6",
   "metadata": {},
   "source": [
    "Activate the Provider Agent in Terminal 3:\n",
    "- Open Terminal 3 by running the cell below.\n",
    "- Type `uv run a2a_provider_agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9902b-a152-4204-90f0-e5530f9477bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "url = os.environ.get(\"DLAI_LOCAL_URL\").format(port=8888)\n",
    "IFrame(f\"{url}terminals/3\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1ec42-e882-4a3b-ba27-383c5cae7d6e",
   "metadata": {},
   "source": [
    "## 8.7. Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f178ad7",
   "metadata": {},
   "source": [
    "- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\n",
    "- [LangChain MCP Adapters](https://docs.langchain.com/oss/python/langchain/mcp)\n",
    "- [Equivalent notebook in the course repo](https://github.com/holtskinner/A2AWalkthrough/blob/main/6_A2AxMCPLangGraph.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e431c1e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download\"</em>.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
